{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbiZGAksvAJp",
        "outputId": "d4c00024-ebd2-4e98-9c37-179a191ff051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n",
            "reduced train/val size: 50000 4000 input shape: (32, 32, 3)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 15, 15, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 3, 3, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              2305000   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                10010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,275,906\n",
            "Trainable params: 3,275,906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/70\n",
            "782/782 [==============================] - 21s 12ms/step - loss: 2.0938 - accuracy: 0.2179 - val_loss: 1.8530 - val_accuracy: 0.3370\n",
            "Epoch 2/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.7561 - accuracy: 0.3529 - val_loss: 1.6722 - val_accuracy: 0.3940\n",
            "Epoch 3/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.6315 - accuracy: 0.3987 - val_loss: 1.5728 - val_accuracy: 0.4218\n",
            "Epoch 4/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.5479 - accuracy: 0.4335 - val_loss: 1.5477 - val_accuracy: 0.4433\n",
            "Epoch 5/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.4947 - accuracy: 0.4535 - val_loss: 1.4711 - val_accuracy: 0.4778\n",
            "Epoch 6/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.4470 - accuracy: 0.4740 - val_loss: 1.4433 - val_accuracy: 0.4897\n",
            "Epoch 7/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.4080 - accuracy: 0.4900 - val_loss: 1.4134 - val_accuracy: 0.4983\n",
            "Epoch 8/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.3748 - accuracy: 0.5046 - val_loss: 1.3629 - val_accuracy: 0.5153\n",
            "Epoch 9/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.3443 - accuracy: 0.5184 - val_loss: 1.3474 - val_accuracy: 0.5250\n",
            "Epoch 10/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.3181 - accuracy: 0.5290 - val_loss: 1.3135 - val_accuracy: 0.5372\n",
            "Epoch 11/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.2895 - accuracy: 0.5384 - val_loss: 1.2757 - val_accuracy: 0.5420\n",
            "Epoch 12/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.2644 - accuracy: 0.5501 - val_loss: 1.2420 - val_accuracy: 0.5575\n",
            "Epoch 13/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.2420 - accuracy: 0.5613 - val_loss: 1.2325 - val_accuracy: 0.5625\n",
            "Epoch 14/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.2213 - accuracy: 0.5696 - val_loss: 1.2099 - val_accuracy: 0.5688\n",
            "Epoch 15/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.2014 - accuracy: 0.5734 - val_loss: 1.1753 - val_accuracy: 0.5850\n",
            "Epoch 16/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.1783 - accuracy: 0.5847 - val_loss: 1.1494 - val_accuracy: 0.5910\n",
            "Epoch 17/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.1601 - accuracy: 0.5897 - val_loss: 1.1485 - val_accuracy: 0.5955\n",
            "Epoch 18/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.1423 - accuracy: 0.5980 - val_loss: 1.1361 - val_accuracy: 0.5985\n",
            "Epoch 19/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.1221 - accuracy: 0.6050 - val_loss: 1.1049 - val_accuracy: 0.6080\n",
            "Epoch 20/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.1044 - accuracy: 0.6128 - val_loss: 1.0767 - val_accuracy: 0.6227\n",
            "Epoch 21/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.0830 - accuracy: 0.6198 - val_loss: 1.0848 - val_accuracy: 0.6155\n",
            "Epoch 22/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.0693 - accuracy: 0.6243 - val_loss: 1.0413 - val_accuracy: 0.6390\n",
            "Epoch 23/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.0558 - accuracy: 0.6299 - val_loss: 1.0263 - val_accuracy: 0.6420\n",
            "Epoch 24/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.0362 - accuracy: 0.6377 - val_loss: 1.0121 - val_accuracy: 0.6503\n",
            "Epoch 25/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.0223 - accuracy: 0.6410 - val_loss: 1.0099 - val_accuracy: 0.6423\n",
            "Epoch 26/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.0083 - accuracy: 0.6463 - val_loss: 0.9901 - val_accuracy: 0.6475\n",
            "Epoch 27/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.9938 - accuracy: 0.6510 - val_loss: 0.9812 - val_accuracy: 0.6555\n",
            "Epoch 28/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.9761 - accuracy: 0.6573 - val_loss: 0.9569 - val_accuracy: 0.6578\n",
            "Epoch 29/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.9637 - accuracy: 0.6613 - val_loss: 0.9590 - val_accuracy: 0.6578\n",
            "Epoch 30/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.9505 - accuracy: 0.6677 - val_loss: 0.9365 - val_accuracy: 0.6708\n",
            "Epoch 31/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.9320 - accuracy: 0.6735 - val_loss: 0.9296 - val_accuracy: 0.6715\n",
            "Epoch 32/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.9243 - accuracy: 0.6762 - val_loss: 0.9263 - val_accuracy: 0.6743\n",
            "Epoch 33/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.9107 - accuracy: 0.6815 - val_loss: 0.9229 - val_accuracy: 0.6727\n",
            "Epoch 34/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.9026 - accuracy: 0.6842 - val_loss: 0.9038 - val_accuracy: 0.6852\n",
            "Epoch 35/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.8885 - accuracy: 0.6915 - val_loss: 0.9073 - val_accuracy: 0.6780\n",
            "Epoch 36/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.8779 - accuracy: 0.6926 - val_loss: 0.8806 - val_accuracy: 0.6877\n",
            "Epoch 37/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.8662 - accuracy: 0.6992 - val_loss: 0.8773 - val_accuracy: 0.6895\n",
            "Epoch 38/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.8559 - accuracy: 0.7012 - val_loss: 0.8716 - val_accuracy: 0.6963\n",
            "Epoch 39/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.8464 - accuracy: 0.7050 - val_loss: 0.8575 - val_accuracy: 0.6948\n",
            "Epoch 40/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.8341 - accuracy: 0.7094 - val_loss: 0.8384 - val_accuracy: 0.7070\n",
            "Epoch 41/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.8267 - accuracy: 0.7124 - val_loss: 0.8581 - val_accuracy: 0.7005\n",
            "Epoch 42/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.8108 - accuracy: 0.7180 - val_loss: 0.8295 - val_accuracy: 0.7107\n",
            "Epoch 43/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.8058 - accuracy: 0.7193 - val_loss: 0.8211 - val_accuracy: 0.7143\n",
            "Epoch 44/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7922 - accuracy: 0.7259 - val_loss: 0.8202 - val_accuracy: 0.7107\n",
            "Epoch 45/70\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.7863 - accuracy: 0.7256 - val_loss: 0.8167 - val_accuracy: 0.7048\n",
            "Epoch 46/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7756 - accuracy: 0.7279 - val_loss: 0.8064 - val_accuracy: 0.7150\n",
            "Epoch 47/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7719 - accuracy: 0.7320 - val_loss: 0.8078 - val_accuracy: 0.7160\n",
            "Epoch 48/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7581 - accuracy: 0.7354 - val_loss: 0.7899 - val_accuracy: 0.7185\n",
            "Epoch 49/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7460 - accuracy: 0.7390 - val_loss: 0.7788 - val_accuracy: 0.7207\n",
            "Epoch 50/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7374 - accuracy: 0.7436 - val_loss: 0.7824 - val_accuracy: 0.7228\n",
            "Epoch 51/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7301 - accuracy: 0.7457 - val_loss: 0.7814 - val_accuracy: 0.7245\n",
            "Epoch 52/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7236 - accuracy: 0.7485 - val_loss: 0.7856 - val_accuracy: 0.7212\n",
            "Epoch 53/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7130 - accuracy: 0.7534 - val_loss: 0.7672 - val_accuracy: 0.7275\n",
            "Epoch 54/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7077 - accuracy: 0.7543 - val_loss: 0.7861 - val_accuracy: 0.7230\n",
            "Epoch 55/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6998 - accuracy: 0.7584 - val_loss: 0.7541 - val_accuracy: 0.7368\n",
            "Epoch 56/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6940 - accuracy: 0.7586 - val_loss: 0.7655 - val_accuracy: 0.7320\n",
            "Epoch 57/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6840 - accuracy: 0.7602 - val_loss: 0.7510 - val_accuracy: 0.7345\n",
            "Epoch 58/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6742 - accuracy: 0.7653 - val_loss: 0.7392 - val_accuracy: 0.7333\n",
            "Epoch 59/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6654 - accuracy: 0.7676 - val_loss: 0.7400 - val_accuracy: 0.7345\n",
            "Epoch 60/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6587 - accuracy: 0.7727 - val_loss: 0.7444 - val_accuracy: 0.7393\n",
            "Epoch 61/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6548 - accuracy: 0.7724 - val_loss: 0.7379 - val_accuracy: 0.7402\n",
            "Epoch 62/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6467 - accuracy: 0.7750 - val_loss: 0.7246 - val_accuracy: 0.7393\n",
            "Epoch 63/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6368 - accuracy: 0.7787 - val_loss: 0.7282 - val_accuracy: 0.7433\n",
            "Epoch 64/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6284 - accuracy: 0.7822 - val_loss: 0.7161 - val_accuracy: 0.7498\n",
            "Epoch 65/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6221 - accuracy: 0.7834 - val_loss: 0.7336 - val_accuracy: 0.7430\n",
            "Epoch 66/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6132 - accuracy: 0.7890 - val_loss: 0.7062 - val_accuracy: 0.7513\n",
            "Epoch 67/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6062 - accuracy: 0.7898 - val_loss: 0.7113 - val_accuracy: 0.7470\n",
            "Epoch 68/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6014 - accuracy: 0.7922 - val_loss: 0.7096 - val_accuracy: 0.7505\n",
            "Epoch 69/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.5953 - accuracy: 0.7942 - val_loss: 0.7008 - val_accuracy: 0.7558\n",
            "Epoch 70/70\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.5862 - accuracy: 0.7976 - val_loss: 0.6992 - val_accuracy: 0.7495\n",
            "Baseline 정확률은 75.30999779701233\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "74836368/74836368 [==============================] - 0s 0us/step\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet201 (Functional)    (None, 1, 1, 1920)        18321984  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1920)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1000)              1921000   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                10010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,252,994\n",
            "Trainable params: 20,023,938\n",
            "Non-trainable params: 229,056\n",
            "_________________________________________________________________\n",
            "Epoch 1/70\n",
            "782/782 [==============================] - 209s 124ms/step - loss: 1.3868 - accuracy: 0.5260 - val_loss: 0.9919 - val_accuracy: 0.6750\n",
            "Epoch 2/70\n",
            "782/782 [==============================] - 94s 120ms/step - loss: 0.7644 - accuracy: 0.7370 - val_loss: 0.7492 - val_accuracy: 0.7455\n",
            "Epoch 3/70\n",
            "782/782 [==============================] - 94s 120ms/step - loss: 0.5545 - accuracy: 0.8082 - val_loss: 0.6954 - val_accuracy: 0.7657\n",
            "Epoch 4/70\n",
            "782/782 [==============================] - 94s 121ms/step - loss: 0.4054 - accuracy: 0.8627 - val_loss: 0.6756 - val_accuracy: 0.7780\n",
            "Epoch 5/70\n",
            "782/782 [==============================] - 95s 122ms/step - loss: 0.2872 - accuracy: 0.9036 - val_loss: 0.6691 - val_accuracy: 0.7905\n",
            "Epoch 6/70\n",
            "782/782 [==============================] - 94s 121ms/step - loss: 0.1933 - accuracy: 0.9379 - val_loss: 0.6961 - val_accuracy: 0.7937\n",
            "Epoch 7/70\n",
            "782/782 [==============================] - 93s 119ms/step - loss: 0.1336 - accuracy: 0.9582 - val_loss: 0.7340 - val_accuracy: 0.8010\n",
            "Epoch 8/70\n",
            "782/782 [==============================] - 92s 118ms/step - loss: 0.0957 - accuracy: 0.9709 - val_loss: 0.7633 - val_accuracy: 0.8012\n",
            "Epoch 9/70\n",
            "782/782 [==============================] - 92s 117ms/step - loss: 0.0792 - accuracy: 0.9752 - val_loss: 0.8208 - val_accuracy: 0.7955\n",
            "Epoch 10/70\n",
            "782/782 [==============================] - 94s 120ms/step - loss: 0.0664 - accuracy: 0.9788 - val_loss: 0.8365 - val_accuracy: 0.8075\n",
            "Epoch 11/70\n",
            "782/782 [==============================] - 94s 120ms/step - loss: 0.0561 - accuracy: 0.9828 - val_loss: 0.8469 - val_accuracy: 0.8117\n",
            "Epoch 12/70\n",
            "782/782 [==============================] - 93s 119ms/step - loss: 0.0504 - accuracy: 0.9840 - val_loss: 0.8876 - val_accuracy: 0.8080\n",
            "Epoch 13/70\n",
            "782/782 [==============================] - 92s 118ms/step - loss: 0.0424 - accuracy: 0.9866 - val_loss: 0.9197 - val_accuracy: 0.8030\n",
            "Epoch 14/70\n",
            "782/782 [==============================] - 92s 118ms/step - loss: 0.0413 - accuracy: 0.9863 - val_loss: 0.9314 - val_accuracy: 0.8058\n",
            "Epoch 15/70\n",
            "782/782 [==============================] - 92s 118ms/step - loss: 0.0399 - accuracy: 0.9873 - val_loss: 0.9102 - val_accuracy: 0.8083\n",
            "Epoch 16/70\n",
            "782/782 [==============================] - 94s 120ms/step - loss: 0.0368 - accuracy: 0.9882 - val_loss: 0.9183 - val_accuracy: 0.8123\n",
            "Epoch 17/70\n",
            "782/782 [==============================] - 95s 122ms/step - loss: 0.0311 - accuracy: 0.9891 - val_loss: 0.9607 - val_accuracy: 0.8123\n",
            "Epoch 18/70\n",
            "782/782 [==============================] - 95s 121ms/step - loss: 0.0342 - accuracy: 0.9894 - val_loss: 0.9775 - val_accuracy: 0.8055\n",
            "Epoch 19/70\n",
            "782/782 [==============================] - 95s 121ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.9713 - val_accuracy: 0.8092\n",
            "Epoch 20/70\n",
            "782/782 [==============================] - 94s 121ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.9902 - val_accuracy: 0.8138\n",
            "Epoch 21/70\n",
            "782/782 [==============================] - 94s 120ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.9947 - val_accuracy: 0.8135\n",
            "Epoch 22/70\n",
            "782/782 [==============================] - 93s 120ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 0.9972 - val_accuracy: 0.8158\n",
            "Epoch 23/70\n",
            "782/782 [==============================] - 92s 118ms/step - loss: 0.0298 - accuracy: 0.9908 - val_loss: 0.9936 - val_accuracy: 0.8083\n",
            "Epoch 24/70\n",
            "782/782 [==============================] - 92s 118ms/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.9836 - val_accuracy: 0.8142\n",
            "Epoch 25/70\n",
            "782/782 [==============================] - 93s 119ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 1.0036 - val_accuracy: 0.8207\n",
            "Epoch 26/70\n",
            "782/782 [==============================] - 94s 120ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 1.0023 - val_accuracy: 0.8195\n",
            "Epoch 27/70\n",
            "782/782 [==============================] - 92s 118ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 1.0467 - val_accuracy: 0.8117\n",
            "Epoch 28/70\n",
            "782/782 [==============================] - 92s 118ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 1.0335 - val_accuracy: 0.8148\n",
            "Epoch 29/70\n",
            "782/782 [==============================] - 94s 120ms/step - loss: 0.0194 - accuracy: 0.9934 - val_loss: 1.0364 - val_accuracy: 0.8223\n",
            "Epoch 30/70\n",
            "782/782 [==============================] - 94s 120ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 1.0310 - val_accuracy: 0.8225\n",
            "Epoch 31/70\n",
            "782/782 [==============================] - 94s 120ms/step - loss: 0.0188 - accuracy: 0.9934 - val_loss: 1.0256 - val_accuracy: 0.8282\n",
            "Epoch 32/70\n",
            "782/782 [==============================] - 93s 119ms/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 1.0259 - val_accuracy: 0.8200\n",
            "Epoch 33/70\n",
            "782/782 [==============================] - 93s 120ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 1.0272 - val_accuracy: 0.8180\n",
            "Epoch 34/70\n",
            "782/782 [==============================] - 94s 121ms/step - loss: 0.0166 - accuracy: 0.9945 - val_loss: 1.0188 - val_accuracy: 0.8225\n",
            "Epoch 35/70\n",
            "782/782 [==============================] - 93s 119ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 1.0337 - val_accuracy: 0.8265\n",
            "Epoch 36/70\n",
            "782/782 [==============================] - 93s 119ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 1.0169 - val_accuracy: 0.8250\n",
            "Epoch 37/70\n",
            "782/782 [==============================] - 93s 119ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 1.0023 - val_accuracy: 0.8250\n",
            "Epoch 38/70\n",
            "782/782 [==============================] - 93s 119ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 1.0301 - val_accuracy: 0.8202\n",
            "Epoch 39/70\n",
            "782/782 [==============================] - 94s 120ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 1.0319 - val_accuracy: 0.8280\n",
            "Epoch 40/70\n",
            "782/782 [==============================] - 97s 124ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 1.0104 - val_accuracy: 0.8300\n",
            "Epoch 41/70\n",
            "782/782 [==============================] - 95s 122ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 1.0230 - val_accuracy: 0.8232\n",
            "Epoch 42/70\n",
            "782/782 [==============================] - 95s 122ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 1.0445 - val_accuracy: 0.8160\n",
            "Epoch 43/70\n",
            "782/782 [==============================] - 96s 123ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 1.0131 - val_accuracy: 0.8188\n",
            "Epoch 44/70\n",
            "782/782 [==============================] - 95s 121ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 1.0245 - val_accuracy: 0.8273\n",
            "Epoch 45/70\n",
            "782/782 [==============================] - 95s 121ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 1.0387 - val_accuracy: 0.8300\n",
            "Epoch 46/70\n",
            "782/782 [==============================] - 96s 123ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 1.0638 - val_accuracy: 0.8235\n",
            "Epoch 47/70\n",
            "782/782 [==============================] - 94s 121ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 1.0303 - val_accuracy: 0.8292\n",
            "Epoch 48/70\n",
            "782/782 [==============================] - 94s 120ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 1.0604 - val_accuracy: 0.8273\n",
            "Epoch 49/70\n",
            "782/782 [==============================] - 95s 122ms/step - loss: 0.0138 - accuracy: 0.9958 - val_loss: 1.0103 - val_accuracy: 0.8360\n",
            "Epoch 50/70\n",
            "782/782 [==============================] - 94s 121ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 1.0350 - val_accuracy: 0.8328\n",
            "Epoch 51/70\n",
            "782/782 [==============================] - 92s 118ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 1.0787 - val_accuracy: 0.8280\n",
            "Epoch 52/70\n",
            "782/782 [==============================] - 93s 119ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 1.0825 - val_accuracy: 0.8257\n",
            "Epoch 53/70\n",
            "782/782 [==============================] - 93s 119ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 1.0788 - val_accuracy: 0.8282\n",
            "Epoch 54/70\n",
            "782/782 [==============================] - 92s 118ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 1.0219 - val_accuracy: 0.8338\n",
            "Epoch 55/70\n",
            "782/782 [==============================] - 92s 118ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 1.0662 - val_accuracy: 0.8292\n",
            "Epoch 56/70\n",
            "782/782 [==============================] - 92s 118ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 1.0417 - val_accuracy: 0.8265\n",
            "Epoch 57/70\n",
            "782/782 [==============================] - 92s 118ms/step - loss: 0.0121 - accuracy: 0.9962 - val_loss: 1.0287 - val_accuracy: 0.8325\n",
            "Epoch 58/70\n",
            "782/782 [==============================] - 92s 118ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 1.0533 - val_accuracy: 0.8322\n",
            "Epoch 59/70\n",
            "782/782 [==============================] - 94s 120ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 1.0457 - val_accuracy: 0.8313\n",
            "Epoch 60/70\n",
            "782/782 [==============================] - 92s 118ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 1.0306 - val_accuracy: 0.8292\n",
            "Epoch 61/70\n",
            "782/782 [==============================] - 92s 117ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.9979 - val_accuracy: 0.8388\n",
            "Epoch 62/70\n",
            "782/782 [==============================] - 91s 117ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 1.0202 - val_accuracy: 0.8388\n",
            "Epoch 63/70\n",
            "782/782 [==============================] - 91s 116ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 1.0276 - val_accuracy: 0.8372\n",
            "Epoch 64/70\n",
            "782/782 [==============================] - 91s 116ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 1.0562 - val_accuracy: 0.8290\n",
            "Epoch 65/70\n",
            "782/782 [==============================] - 91s 116ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 1.0489 - val_accuracy: 0.8325\n",
            "Epoch 66/70\n",
            "782/782 [==============================] - 91s 117ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 1.0824 - val_accuracy: 0.8313\n",
            "Epoch 67/70\n",
            "782/782 [==============================] - 92s 117ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 1.0392 - val_accuracy: 0.8325\n",
            "Epoch 68/70\n",
            "782/782 [==============================] - 91s 116ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 1.0365 - val_accuracy: 0.8315\n",
            "Epoch 69/70\n",
            "782/782 [==============================] - 91s 116ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 1.0663 - val_accuracy: 0.8385\n",
            "Epoch 70/70\n",
            "782/782 [==============================] - 92s 117ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 1.0757 - val_accuracy: 0.8338\n",
            "Baseline vs yours:  75.30999779701233 83.31000208854675\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"과제5 CNN기반 영상분류문제\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1Py2GvZc1GwqNbrR4fuQrHFy6zBEdF1xF\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
        "x_train=x_train.astype(np.float32)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
        "\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "x_val, _, y_val,_ = train_test_split(x_test, y_test, test_size=0.6, random_state=1)\n",
        "\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "#동일조건 유지해야 하는 변수(두 모델 모두 동일하게 적용해야 함)\n",
        "g_epoch = 70\n",
        "g_batch = 64\n",
        "\n",
        "#중요 : 아래함수 변경 불가!\n",
        "def reset_random_seeds():\n",
        "   os.environ['PYTHONHASHSEED']=str(1)\n",
        "   tf.random.set_seed(1)\n",
        "   np.random.seed(1)\n",
        "   random.seed(1)\n",
        "   os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "reset_random_seeds() #필수\n",
        "   \n",
        "print(\"reduced train/val size:\", len(x_train), len(x_val), \"input shape:\", input_shape)\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "\n",
        "tf.__version__\n",
        "\n",
        "from tensorflow.keras.layers import MaxPooling2D, Dropout, Conv2D\n",
        "\n",
        "cnn=Sequential()\n",
        "cnn.add(Conv2D(64,(3,3),activation='relu',input_shape=(32,32,3)))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Dropout(0.25))\n",
        "cnn.add(Conv2D(128,(3,3),activation='relu', padding='same'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Dropout(0.25))\n",
        "cnn.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n",
        "cnn.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(1000,activation='relu'))\n",
        "cnn.add(Dropout(0.5))\n",
        "cnn.add(Dense(10,activation='softmax'))\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy',optimizer=Adam(0.00002),metrics=['accuracy'])\n",
        "cnn.summary()\n",
        "\n",
        "hist=cnn.fit(x_train, y_train, batch_size=g_batch, epochs=g_epoch,\n",
        "             validation_data=(x_val,y_val), verbose=1)\n",
        "\n",
        "g_org_res=cnn.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"Baseline 정확률은\",g_org_res[1]*100)\n",
        "\n",
        "no_class = 10\n",
        "\n",
        "# for transfer learning only\n",
        "from tensorflow.keras.applications import densenet\n",
        "\n",
        "os.environ['PYTHONHASHSEED']=str(1)\n",
        "tf.random.set_seed(1)\n",
        "np.random.seed(1)\n",
        "random.seed(1)\n",
        "\n",
        "# for transfer learning only\n",
        "transfermodel = densenet.DenseNet201(weights='imagenet',include_top=False,\n",
        "                    input_shape=input_shape)\n",
        "#base_model.trainable=False     # it's up to you\n",
        "\n",
        "# your model architecture\n",
        "model=Sequential()\n",
        "# 전처리 레이어 추가/변경 가능\n",
        "model.add(transfermodel)    # for transfer learning only\n",
        "model.add(Flatten())        # for transfer learning only\n",
        "model.add(Dense(1000,activation='relu')) # <<-- 변경가능\n",
        "model.add(Dense(no_class, activation='softmax')) # <<-- activation은 변경가능\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(0.00002),metrics=['accuracy']) # <<-- 변경가능\n",
        "model.summary()\n",
        "\n",
        "hist=model.fit(x_train, y_train, batch_size=g_batch, epochs=g_epoch,\n",
        "             validation_data=(x_val,y_val), verbose=1)\n",
        "\n",
        "yours=model.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"Baseline vs yours: \",g_org_res[1]*100, yours[1]*100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import sys\n",
        "\n",
        "print(\"sklearn version\", sklearn.__version__)\n",
        "print(\"tensorflow version\", tf.__version__)\n",
        "print(\"python version\", sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djB64UQGLJ9N",
        "outputId": "55f93ef0-aeb6-42f6-e3a8-8b0e53c3beae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sklearn version 1.2.2\n",
            "tensorflow version 2.12.0\n",
            "python version 3.9.16 (main, Dec  7 2022, 01:11:51) \n",
            "[GCC 9.4.0]\n"
          ]
        }
      ]
    }
  ]
}